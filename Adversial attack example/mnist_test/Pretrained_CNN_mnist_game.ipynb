{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a1707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95ef024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x213a8ecbd30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7e9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7055334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "data_type=torch.float32\n",
    "MOMENTUM = 0.99\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afcfa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    batch_size = 500\n",
    "    \n",
    "    totalT=2.0;\n",
    "    \n",
    "    n_layer=Ntime=4; \n",
    "    \n",
    "    sqrt_deltaT=np.sqrt(totalT/Ntime); \n",
    "\n",
    "    logging_frequency = 100\n",
    "    verbose = True\n",
    "   \n",
    "    input_chanel=1\n",
    "    output_chanel_pj1=32\n",
    "    output_chanel_pj2=16 \n",
    "    \n",
    "    unflatten_shape=output_chanel_pj2*7*7\n",
    "    \n",
    "def get_config(name):\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except KeyError:\n",
    "        raise KeyError(\"config not defined.\")\n",
    "cfg=get_config('Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944b4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train=cfg.batch_size\n",
    "batch_size_test=cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca85ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c031d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249b8c7",
   "metadata": {},
   "source": [
    "## Plain vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bc1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjBlock(nn.Module):\n",
    "    def __init__(self,input_chanel,output_chanel):\n",
    "        super(ProjBlock,self).__init__()\n",
    "        self.input_chanel=input_chanel\n",
    "        self.output_chanel=output_chanel\n",
    "        \n",
    "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "        self.act1=nn.Tanh()\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        \n",
    "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "      #  self.act1=nn.Tanh()\n",
    "      #  self.pool1=nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2096d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,num_chanel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.input_chanel=num_chanel\n",
    "        self.output_chanel=num_chanel\n",
    "        \n",
    "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
    "        self.act=nn.Tanh()\n",
    "        ## there should not be any MaxPooling layer in the inbetween set\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.act(self.conv(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed849160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,unflatten_shape): \n",
    "        super(FullyConnected,self).__init__()\n",
    "        self.unflatten_shape=unflatten_shape\n",
    "        self.fc1=nn.Linear(unflatten_shape,32)\n",
    "        self.ac1=nn.Tanh()\n",
    "        self.fc2=nn.Linear(32,10) \n",
    "        # Let's only tell the airplane from a bird\n",
    "    \n",
    "    def forward(self,x):\n",
    "        inputx=x.view(-1, self.unflatten_shape)\n",
    "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ec4b4",
   "metadata": {},
   "source": [
    "## Stacking up the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6afaeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f45394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(ForwardModel,self).__init__()\n",
    "        \n",
    "        self.config=config\n",
    "        self.batch_size=self.config.batch_size\n",
    "        self.Ntime=self.config.Ntime\n",
    "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
    "        self.n_layer=self.config.n_layer\n",
    "        \n",
    "        ## The structure is merely a stack-up of the convolutional blocks\n",
    "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
    "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  FullyConnected(self.config.unflatten_shape)                              \n",
    "        ])\n",
    "    \n",
    "    def forward(self,data):\n",
    "        data_temp=torch.clone(data)\n",
    "        for block in self.mList:\n",
    "            data_temp=block(data_temp)\n",
    "        return data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217de242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_accuracy(model,train_loader):\n",
    "    total=0;\n",
    "    correct=0;\n",
    "    for imgs,labels in train_loader: \n",
    "        imgs, labels=imgs.to(device), labels.to(device)\n",
    "        output=model(imgs)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        \n",
    "        total += imgs.shape[0]\n",
    "        correct += int((predicted == labels.to(device)).sum())\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "952e8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "# which also works in the batch case\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "#    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15c854",
   "metadata": {},
   "source": [
    "### We now read the coefficient of the plain vanilla nn\n",
    "\n",
    "The train accuracy after 8 epochs achieves 99.2%, and the test accuracy achieves 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39da22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model='data/VanillaCNN_mnist_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa466a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ForwardModel(cfg)\n",
    "net.to(device);\n",
    "net.load_state_dict(torch.load(pretrained_model, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940fd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48ca95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The net will only evaluate samples from now\n",
    "#net.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da542d93",
   "metadata": {},
   "source": [
    "## In this part we let the attacker and the model play games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d14ff753",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data=example_data.to(device)\n",
    "example_targets=example_targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8cdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "correct_post=0\n",
    "total_post=0\n",
    "\n",
    "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec04ed8",
   "metadata": {},
   "source": [
    "net.eval()\n",
    "example_data.requires_grad=True\n",
    "output=net(example_data)\n",
    "loss=loss_fn(output,example_targets)\n",
    "_,pred=torch.max(output,dim=1)\n",
    "net.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "data_grad=example_data.grad.data # you can obtain the grad in this way??? \n",
    "peturbed_data=fgsm_attack(example_data,0.2,data_grad)\n",
    "output_attack=net(peturbed_data)\n",
    "_,pred_attack=torch.max(output_attack, dim=1)\n",
    "\n",
    "\n",
    "correct += int((pred_attack.to(device) == example_targets.to(device)).sum())\n",
    "total += example_data.shape[0]\n",
    "correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb361e",
   "metadata": {},
   "source": [
    "# Now we need to train the model\n",
    "# Set the data to be untrainable\n",
    "peturbed_data= peturbed_data.detach()\n",
    "net.train() #Now we set the net to train mode\n",
    "output_post=net(peturbed_data)\n",
    "loss_attack=loss_fn(output_attack, example_targets)\n",
    "loss_attack.to(device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss_attack.backward()\n",
    "optimizer.step()\n",
    "\n",
    "output_trained=net(peturbed_data)\n",
    "_,pred_trained=torch.max(output_trained, dim=1)\n",
    "\n",
    "correct_post += int((pred_trained.to(device) == example_targets.to(device)).sum())\n",
    "total_post += example_data.shape[0]\n",
    "correct_post/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b352ca1",
   "metadata": {},
   "source": [
    "### Run this all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d4495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct_0=0 \n",
    "total_0=0\n",
    "\n",
    "for imgs, labels in test_loader:\n",
    "    imgs, labels=imgs.to(device), labels.to(device)\n",
    "    imgs.requires_grad=True\n",
    " \n",
    "    output=net(imgs)\n",
    "    _,pred=torch.max(output,dim=1)\n",
    "    correct_0 += int((pred.to(device) == labels.to(device)).sum())\n",
    "    total_0 += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb5d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_0/total_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20c83ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ForwardModel(cfg)\n",
    "net.to(device);\n",
    "net.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "correct_post=0\n",
    "total_post=0\n",
    "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
    "\n",
    "attack_epsilon=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72080bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels=imgs.to(device), labels.to(device)\n",
    "        imgs.requires_grad=True\n",
    "\n",
    "        ### Attacker starts to work ### \n",
    "        net.eval()\n",
    "        output=net(imgs)\n",
    "        loss=loss_fn(output,labels)\n",
    "        _,pred=torch.max(output,dim=1)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad=imgs.grad.data # you can obtain the grad in this way??? \n",
    "        peturbed_data=fgsm_attack(imgs,attack_epsilon,data_grad)\n",
    "        output_attack=net(peturbed_data)\n",
    "        _,pred_attack=torch.max(output_attack, dim=1)\n",
    "\n",
    "\n",
    "        correct += int((pred_attack.to(device) == labels.to(device)).sum())\n",
    "        total += imgs.shape[0]\n",
    "\n",
    "        ### Self-correction made by the model ### \n",
    "        peturbed_data= peturbed_data.detach()\n",
    "        net.train() #Now we set the net to train mode\n",
    "        output_post=net(peturbed_data)\n",
    "        loss_attack=loss_fn(output_attack, labels)\n",
    "        loss_attack.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output_trained=net(peturbed_data)\n",
    "        _,pred_trained=torch.max(output_trained, dim=1)\n",
    "\n",
    "        correct_post += int((pred_trained.to(device) == labels.to(device)).sum())\n",
    "        total_post += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b641fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68816, 0.69938)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total, correct_post/total_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7b6a3",
   "metadata": {},
   "source": [
    "As a result, facing the attack, it will have accuarcy of 0.6981. \n",
    "How about the natural accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ad7dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct_natural=0 \n",
    "total_natural=0\n",
    "\n",
    "for imgs, labels in test_loader:\n",
    "    imgs, labels=imgs.to(device), labels.to(device)\n",
    "    imgs.requires_grad=True\n",
    " \n",
    "    output=net(imgs)\n",
    "    _,pred=torch.max(output,dim=1)\n",
    "    correct_natural += int((pred.to(device) == labels.to(device)).sum())\n",
    "    total_natural += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa4fc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_natural/total_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fe43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fae55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbee55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
