{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64051f42",
   "metadata": {
    "id": "64051f42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sThDQwu9_MY6",
   "metadata": {
    "id": "sThDQwu9_MY6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9d4a68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d9d4a68",
    "outputId": "7b9d3a4d-e611-4d9e-ba46-d23d29fc310d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2593caa5b90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8048c60",
   "metadata": {
    "id": "a8048c60"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VEXLxVU3HSjm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEXLxVU3HSjm",
    "outputId": "dff79d23-b2bb-49e1-cf62-191f3f6cbbca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "data_type=torch.float32\n",
    "MOMENTUM = 0.99\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043871cf",
   "metadata": {
    "id": "043871cf"
   },
   "source": [
    "# Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b3546f",
   "metadata": {
    "id": "e9b3546f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb0197",
   "metadata": {
    "id": "bceb0197"
   },
   "source": [
    "We have stored both the training and the validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70444346",
   "metadata": {
    "id": "70444346"
   },
   "source": [
    "Defining the dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78047303",
   "metadata": {
    "id": "78047303"
   },
   "source": [
    "## Defining the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be29e470",
   "metadata": {
    "id": "be29e470"
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    batch_size = 500\n",
    "    \n",
    "    totalT=2.0;\n",
    "    \n",
    "    n_layer=Ntime=4; \n",
    "    \n",
    "    sqrt_deltaT=np.sqrt(totalT/Ntime); \n",
    "\n",
    "    logging_frequency = 100\n",
    "    verbose = True\n",
    "   \n",
    "    input_chanel=1\n",
    "    output_chanel_pj1=32\n",
    "    output_chanel_pj2=16 \n",
    "    \n",
    "    unflatten_shape=output_chanel_pj2*7*7\n",
    "    \n",
    "def get_config(name):\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except KeyError:\n",
    "        raise KeyError(\"config not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c411bccd",
   "metadata": {
    "id": "c411bccd"
   },
   "outputs": [],
   "source": [
    "cfg=get_config('Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "HmoJLSpp9XRc",
   "metadata": {
    "id": "HmoJLSpp9XRc"
   },
   "outputs": [],
   "source": [
    "batch_size_train=cfg.batch_size\n",
    "batch_size_test=cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "swbVuiTI9e_U",
   "metadata": {
    "id": "swbVuiTI9e_U"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('/files/', train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=cfg.batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('/files/', train=False, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=cfg.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "L0RJqlMl9kC1",
   "metadata": {
    "id": "L0RJqlMl9kC1"
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bcc53",
   "metadata": {
    "id": "407bcc53"
   },
   "source": [
    "# Constructing a dense net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefbf48",
   "metadata": {
    "id": "5fefbf48"
   },
   "source": [
    "## Building the building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a33786",
   "metadata": {
    "id": "96a33786"
   },
   "outputs": [],
   "source": [
    "class ProjBlock(nn.Module):\n",
    "    def __init__(self,input_chanel,output_chanel):\n",
    "        super(ProjBlock,self).__init__()\n",
    "        self.input_chanel=input_chanel\n",
    "        self.output_chanel=output_chanel\n",
    "        \n",
    "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "        self.act1=nn.Tanh()\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        \n",
    "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "      #  self.act1=nn.Tanh()\n",
    "      #  self.pool1=nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f600188",
   "metadata": {
    "id": "3f600188"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,num_chanel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.input_chanel=num_chanel\n",
    "        self.output_chanel=num_chanel\n",
    "        \n",
    "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
    "        self.act=nn.Tanh()\n",
    "        ## there should not be any MaxPooling layer in the inbetween set\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.act(self.conv(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ff83cf",
   "metadata": {
    "id": "41ff83cf"
   },
   "outputs": [],
   "source": [
    "# One is responsible for figuring out the unflatten shape\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,unflatten_shape): \n",
    "        super(FullyConnected,self).__init__()\n",
    "        self.unflatten_shape=unflatten_shape\n",
    "        self.fc1=nn.Linear(unflatten_shape,32)\n",
    "        self.ac1=nn.Tanh()\n",
    "        self.fc2=nn.Linear(32,10) \n",
    "        # Let's only tell the airplane from a bird\n",
    "    \n",
    "    def forward(self,x):\n",
    "        inputx=x.view(-1, self.unflatten_shape)\n",
    "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec1467",
   "metadata": {
    "id": "30ec1467"
   },
   "source": [
    "## Stacking up the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eebf8c6",
   "metadata": {
    "id": "0eebf8c6"
   },
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(ForwardModel,self).__init__()\n",
    "        \n",
    "        self.config=config\n",
    "        self.batch_size=self.config.batch_size\n",
    "        self.Ntime=self.config.Ntime\n",
    "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
    "        self.n_layer=self.config.n_layer\n",
    "        self.delta=self.config.totalT/self.Ntime;\n",
    "        \n",
    "        ## The structure is merely a stack-up of the convolutional blocks\n",
    "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
    "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  FullyConnected(self.config.unflatten_shape)                              \n",
    "        ])\n",
    "        \n",
    "        self.sigma=0.25\n",
    "        \n",
    "    def forwardX(self,x):# here x is the batch collection of images\n",
    "        \n",
    "        # Constructing the noises\n",
    "        # The number 8 is determined from the number of max-pooling size, kernels & paddings etc. \n",
    "        xMat=[]\n",
    "        wMat=torch.FloatTensor(normal.rvs(size=[self.batch_size,\n",
    "                                     self.config.output_chanel_pj2,7,7,\n",
    "                                     self.Ntime]) * self.sqrt_deltaT).to(device)\n",
    "        x0=torch.clone(x).to(device); \n",
    "        xMat.append(x0); \n",
    "        \n",
    "        x_pj1=self.mList[0](x0); \n",
    "        xMat.append(x_pj1.to(device)); \n",
    "        x_input=self.mList[1](x_pj1)\n",
    "        xMat.append(x_input.to(device));\n",
    "        \n",
    "        for i in range(self.Ntime):\n",
    "            # i + 2 because we already have two layers before\n",
    "            xtemp=xMat[i+2]+self.mList[i+2](xMat[i+2])*self.delta +self.sigma*wMat[:,:,:,:,i] \n",
    "            xMat.append(xtemp.to(device))\n",
    "        \n",
    "        x_terminal=self.mList[-1](xMat[-1])\n",
    "        xMat.append(x_terminal.to(device))\n",
    "        \n",
    "        \n",
    "        return xMat, wMat\n",
    "        \n",
    "        # The input of the target must be a tensor not a list\n",
    "    def backwardYZ(self,xMat,wMat,target):\n",
    "        yMat=[];  \n",
    "        \n",
    "        L=len(xMat)\n",
    "        x_terminal=xMat[-1].to(device)\n",
    "        \n",
    "        loss_val=loss_fn(x_terminal,target.to(device))\n",
    "        loss_val.to(device); \n",
    "        \n",
    "        y_terminal=torch.autograd.grad(outputs=[loss_val], inputs=[x_terminal], grad_outputs=torch.ones_like(loss_val), allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        #Here y_terminal has dim batch_size x output_size (2 x 2)\n",
    "        yMat.append(y_terminal.to(device)); \n",
    "        xtemp=xMat[L-2].to(device) # 3 \n",
    "        \n",
    "        ## Finding Y[T-1]\n",
    "        hami=torch.sum(y_terminal.detach()*self.mList[-1](xtemp),dim=1,keepdim=True) # keep dim=1 is correct\n",
    "        hami=hami.view(-1,1);hami.to(device)\n",
    "\n",
    "        hami_x=torch.autograd.grad(outputs=[hami], inputs=[xtemp], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "        yMat.append(hami_x.to(device))\n",
    "        \n",
    "        for i in range(self.Ntime-1,-1,-1):\n",
    "            X=xMat[i+2].to(device); \n",
    "            hami=torch.sum(yMat[-1].detach()*self.mList[i+2](X),dim=(1,2,3))\n",
    "            hami=hami.view(-1,1); hami.to(device); \n",
    "            \n",
    "            hami_x=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "            ytemp=yMat[-1]+hami_x*self.delta\n",
    "\n",
    "            yMat.append(ytemp.to(device))\n",
    "       \n",
    "    ### Second projection layer\n",
    "        X=xMat[1].to(device); \n",
    "       # X.requires_grad\n",
    "        hami=torch.sum(yMat[-1].detach()*self.mList[1](X),dim=(1,2,3))\n",
    "        hami=hami.view(-1,1); hami.to(device); \n",
    "            \n",
    "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        yMat.append(ytemp.to(device))\n",
    "        \n",
    "        X=xMat[0].to(device); \n",
    "        X.requires_grad=True\n",
    "        hami=torch.sum(yMat[-1].detach()*self.mList[0](X),dim=(1,2,3))\n",
    "        hami=hami.view(-1,1); hami.to(device)\n",
    "            \n",
    "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        yMat.append(ytemp.to(device))\n",
    "        \n",
    "        return yMat  #yMat the order is reversed \n",
    "    \n",
    "    def HamCompute(self,xMat,yMat):\n",
    "        totalham=0.0\n",
    "        \n",
    "        for i in range(self.Ntime+3):\n",
    "            ham_temp=torch.sum(yMat[self.Ntime+2-i].detach()*self.mList[i](xMat[i].detach()) )  #inside the bracket =  +\\small_value * self.batch_size *self.mList[i]*self.mList[i] (No, this doesn't contain batchsize)\n",
    "            totalham+=ham_temp\n",
    "        \n",
    "        return totalham/self.batch_size/(self.Ntime+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9RylV-3v1r1l",
   "metadata": {
    "id": "9RylV-3v1r1l"
   },
   "outputs": [],
   "source": [
    "def train_accuracy(train_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in train_loader:\n",
    "            outputs = net.forwardX(imgs)\n",
    "            _, predicted = torch.max(outputs[0][-1], dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels.to(device)).sum())\n",
    "    res=correct/total\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f95be8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f95be8f",
    "outputId": "e039bf33-b875-4185-da2c-b204a90569f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.48475507\n",
      "0.8252\n",
      "0.8342833333333334\n",
      "2 0.28482863\n",
      "0.867\n",
      "0.8791166666666667\n",
      "4 0.3184092\n",
      "0.8816\n",
      "0.8979666666666667\n",
      "6 0.2999456\n",
      "0.8916\n",
      "0.9093166666666667\n",
      "8 0.26543495\n",
      "0.8919\n",
      "0.9086\n"
     ]
    }
   ],
   "source": [
    "n_epoch=10\n",
    "\n",
    "net=ForwardModel(cfg)\n",
    "net.to(device)\n",
    "\n",
    "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2500,4000], gamma=0.2) \n",
    "\n",
    "Loss_vec=[]\n",
    "training_accuracy=[]\n",
    "testing_accuracy=[]\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "\n",
    "        xmat,wmat=net.forwardX(imgs); \n",
    "        ymat=net.backwardYZ(xmat,wmat.to(device),labels)\n",
    "        loss_temp=net.HamCompute(xmat,ymat)\n",
    "        loss_temp.to(device)\n",
    "        \n",
    "        optimizer.zero_grad();\n",
    "        loss_temp.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch %2 ==0:\n",
    "        loss_val=loss_fn(xmat[-1].to(device),labels.to(device))\n",
    "       # ham_loss=net.HamCompute(xmat,ymat)\n",
    "       # print(ham_loss.cpu().detach().numpy(), loss_val.cpu().detach().numpy())\n",
    "        loss_val_np=loss_val.cpu().detach().numpy()\n",
    "        print(epoch, loss_val_np)\n",
    "        Loss_vec.append(loss_val_np)\n",
    "\n",
    "    #if epoch %10 ==0: \n",
    "        test_temp=train_accuracy(test_loader)\n",
    "        testing_accuracy.append(test_temp)\n",
    "        print(test_temp)\n",
    "\n",
    "        train_temp=train_accuracy(train_loader)\n",
    "        training_accuracy.append(train_temp)\n",
    "        print(train_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ad931",
   "metadata": {},
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3091d",
   "metadata": {},
   "source": [
    "The training accuracy achieves 99.15%, and the test accuracy achieves 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0d71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/SNN_fashion_mnist_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab2731f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34577b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd6f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3020b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f271e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11_eQei6Rwr",
   "metadata": {
    "id": "b11_eQei6Rwr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eed3bb",
   "metadata": {
    "id": "40eed3bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55b942",
   "metadata": {
    "id": "ec55b942"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfc9c0",
   "metadata": {
    "id": "90dfc9c0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f3bfb",
   "metadata": {
    "id": "332f3bfb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319adca",
   "metadata": {
    "id": "1319adca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be28a50",
   "metadata": {
    "id": "1be28a50"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_hand_digits.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
