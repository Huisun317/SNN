{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557dd0ca",
   "metadata": {},
   "source": [
    "### Conventional CNN\n",
    "The attacker attacks the well trained neural network, while the nn itself tries to learn from the attacked data. Results will be used to compare with that of the SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a1707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95ef024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x260c3b45cb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7e9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7055334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "data_type=torch.float32\n",
    "MOMENTUM = 0.99\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afcfa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    batch_size = 500\n",
    "    \n",
    "    totalT=2.0;\n",
    "    \n",
    "    n_layer=Ntime=4; \n",
    "    \n",
    "    sqrt_deltaT=np.sqrt(totalT/Ntime); \n",
    "\n",
    "    logging_frequency = 100\n",
    "    verbose = True\n",
    "   \n",
    "    input_chanel=1\n",
    "    output_chanel_pj1=32\n",
    "    output_chanel_pj2=16 \n",
    "    \n",
    "    unflatten_shape=output_chanel_pj2*7*7\n",
    "    \n",
    "def get_config(name):\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except KeyError:\n",
    "        raise KeyError(\"config not defined.\")\n",
    "cfg=get_config('Config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944b4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train=cfg.batch_size\n",
    "batch_size_test=cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca85ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('/files/', train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=cfg.batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('/files/', train=False, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=cfg.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c031d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249b8c7",
   "metadata": {},
   "source": [
    "## Plain vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95bc1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjBlock(nn.Module):\n",
    "    def __init__(self,input_chanel,output_chanel):\n",
    "        super(ProjBlock,self).__init__()\n",
    "        self.input_chanel=input_chanel\n",
    "        self.output_chanel=output_chanel\n",
    "        \n",
    "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "        self.act1=nn.Tanh()\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        \n",
    "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "      #  self.act1=nn.Tanh()\n",
    "      #  self.pool1=nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f2096d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,num_chanel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.input_chanel=num_chanel\n",
    "        self.output_chanel=num_chanel\n",
    "        \n",
    "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
    "        self.act=nn.Tanh()\n",
    "        ## there should not be any MaxPooling layer in the inbetween set\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.act(self.conv(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed849160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,unflatten_shape): \n",
    "        super(FullyConnected,self).__init__()\n",
    "        self.unflatten_shape=unflatten_shape\n",
    "        self.fc1=nn.Linear(unflatten_shape,32)\n",
    "        self.ac1=nn.Tanh()\n",
    "        self.fc2=nn.Linear(32,10) \n",
    "        # Let's only tell the airplane from a bird\n",
    "    \n",
    "    def forward(self,x):\n",
    "        inputx=x.view(-1, self.unflatten_shape)\n",
    "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ec4b4",
   "metadata": {},
   "source": [
    "## Stacking up the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afaeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f45394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(ForwardModel,self).__init__()\n",
    "        \n",
    "        self.config=config\n",
    "        self.batch_size=self.config.batch_size\n",
    "        self.Ntime=self.config.Ntime\n",
    "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
    "        self.n_layer=self.config.n_layer\n",
    "        \n",
    "        ## The structure is merely a stack-up of the convolutional blocks\n",
    "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
    "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  FullyConnected(self.config.unflatten_shape)                              \n",
    "        ])\n",
    "    \n",
    "    def forward(self,data):\n",
    "        data_temp=torch.clone(data)\n",
    "        for block in self.mList:\n",
    "            data_temp=block(data_temp)\n",
    "        return data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217de242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_accuracy(model,train_loader):\n",
    "    total=0;\n",
    "    correct=0;\n",
    "    for imgs,labels in train_loader: \n",
    "        imgs, labels=imgs.to(device), labels.to(device)\n",
    "        output=model(imgs)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        \n",
    "        total += imgs.shape[0]\n",
    "        correct += int((predicted == labels.to(device)).sum())\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15c854",
   "metadata": {},
   "source": [
    "### We now read the coefficient of the plain vanilla nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39da22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model='data/VanillaCNN_fashion_mnist_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa466a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ForwardModel(cfg)\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1940fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(pretrained_model, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48ca95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The net will only evaluate samples from now\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "569fef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "# which also works in the batch case\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "#    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d90f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it could be a bad idea to add weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4d32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct_0=0 \n",
    "total_0=0\n",
    "\n",
    "for imgs, labels in test_loader:\n",
    "    imgs, labels=imgs.to(device), labels.to(device)\n",
    "    imgs.requires_grad=True\n",
    " \n",
    "    output=net(imgs)\n",
    "    _,pred=torch.max(output,dim=1)\n",
    "    correct_0 += int((pred.to(device) == labels.to(device)).sum())\n",
    "    total_0 += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06e82e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_0/total_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "187da32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ForwardModel(cfg)\n",
    "net.to(device);\n",
    "net.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "correct_post=0\n",
    "total_post=0\n",
    "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)\n",
    "\n",
    "attack_epsilon=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1866c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels=imgs.to(device), labels.to(device)\n",
    "        imgs.requires_grad=True\n",
    "\n",
    "        ### Attacker starts to work ### \n",
    "        net.eval()\n",
    "        output=net(imgs)\n",
    "        loss=loss_fn(output,labels)\n",
    "        _,pred=torch.max(output,dim=1)\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad=imgs.grad.data # you can obtain the grad in this way??? \n",
    "        peturbed_data=fgsm_attack(imgs,attack_epsilon,data_grad)\n",
    "        output_attack=net(peturbed_data)\n",
    "        _,pred_attack=torch.max(output_attack, dim=1)\n",
    "\n",
    "\n",
    "        correct += int((pred_attack.to(device) == labels.to(device)).sum())\n",
    "        total += imgs.shape[0]\n",
    "\n",
    "        ### Self-correction made by the model ### \n",
    "        peturbed_data= peturbed_data.detach()\n",
    "        net.train() #Now we set the net to train mode\n",
    "        output_post=net(peturbed_data)\n",
    "        loss_attack=loss_fn(output_attack, labels)\n",
    "        loss_attack.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output_trained=net(peturbed_data)\n",
    "        _,pred_trained=torch.max(output_trained, dim=1)\n",
    "\n",
    "        correct_post += int((pred_trained.to(device) == labels.to(device)).sum())\n",
    "        total_post += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d053eb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4695"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We point out that this step collects all the correct predictions (for all 5 epochs) \n",
    "### post attack divided by the total samples \n",
    "correct_post/total_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aafbe2f",
   "metadata": {},
   "source": [
    "### Appendix: Check the accuracy of the retrained SNN after attack on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5e5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct_natural=0 \n",
    "total_natural=0\n",
    "\n",
    "for imgs, labels in test_loader:\n",
    "    imgs, labels=imgs.to(device), labels.to(device)\n",
    "    imgs.requires_grad=True\n",
    " \n",
    "    output=net(imgs)\n",
    "    _,pred=torch.max(output,dim=1)\n",
    "    correct_natural += int((pred.to(device) == labels.to(device)).sum())\n",
    "    total_natural += imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7dee31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_natural/total_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e533c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af480887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4b7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
