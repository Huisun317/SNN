## Adversarial Attack

Instead of running a large volume of examples like in Bao Wang etal (https://arxiv.org/abs/1811.10745), we train both the plain vanilla CNN and SNN to the same level accuraccy on both the MNIST and FASHION MNSIT dataset. We show that the SNN performs better facing the adversarial attack.

The folders contain pretrained models together with the parameter file. One can also train the model from scratch by using the scripts given in the folders accordingly.

![attack_fashion_mnist_game](https://user-images.githubusercontent.com/107137651/177045510-9123560a-a0a2-4011-acfe-5e79bbb721dd.png)
