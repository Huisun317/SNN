{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64051f42",
   "metadata": {
    "id": "64051f42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time \n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sThDQwu9_MY6",
   "metadata": {
    "id": "sThDQwu9_MY6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d9d4a68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d9d4a68",
    "outputId": "c408b42a-36f7-4d96-b71e-6da162ad8d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa83c3bee30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8048c60",
   "metadata": {
    "id": "a8048c60"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "VEXLxVU3HSjm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEXLxVU3HSjm",
    "outputId": "c67da321-f5d2-49cb-ce5e-ea0e2726ddc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "data_type=torch.float32\n",
    "MOMENTUM = 0.99\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043871cf",
   "metadata": {
    "id": "043871cf"
   },
   "source": [
    "# Handling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9b3546f",
   "metadata": {
    "id": "e9b3546f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets \n",
    "batch_size_train=cfg.batch_size\n",
    "batch_size_test=cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "gM8FBI_d4lLz",
   "metadata": {
    "id": "gM8FBI_d4lLz"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "n80EcIib4lOl",
   "metadata": {
    "id": "n80EcIib4lOl"
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb0197",
   "metadata": {
    "id": "bceb0197"
   },
   "source": [
    "We have stored both the training and the validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70444346",
   "metadata": {
    "id": "70444346"
   },
   "source": [
    "Defining the dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78047303",
   "metadata": {
    "id": "78047303"
   },
   "source": [
    "## Defining the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be29e470",
   "metadata": {
    "id": "be29e470"
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    batch_size = 200\n",
    "    \n",
    "    totalT=2.0;\n",
    "    \n",
    "    n_layer=Ntime=4; \n",
    "    \n",
    "    sqrt_deltaT=np.sqrt(totalT/Ntime); \n",
    "\n",
    "    logging_frequency = 100\n",
    "    verbose = True\n",
    "   \n",
    "    input_chanel=1\n",
    "    output_chanel_pj1=32\n",
    "    output_chanel_pj2=16 \n",
    "    \n",
    "    unflatten_shape=output_chanel_pj2*7*7\n",
    "    \n",
    "def get_config(name):\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except KeyError:\n",
    "        raise KeyError(\"config not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c411bccd",
   "metadata": {
    "id": "c411bccd"
   },
   "outputs": [],
   "source": [
    "cfg=get_config('Config')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bcc53",
   "metadata": {
    "id": "407bcc53"
   },
   "source": [
    "# Constructing a dense net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefbf48",
   "metadata": {
    "id": "5fefbf48"
   },
   "source": [
    "## Building the building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96a33786",
   "metadata": {
    "id": "96a33786"
   },
   "outputs": [],
   "source": [
    "class ProjBlock(nn.Module):\n",
    "    def __init__(self,input_chanel,output_chanel):\n",
    "        super(ProjBlock,self).__init__()\n",
    "        self.input_chanel=input_chanel\n",
    "        self.output_chanel=output_chanel\n",
    "        \n",
    "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "        self.act1=nn.Tanh()\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        \n",
    "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1) \n",
    "      #  self.act1=nn.Tanh()\n",
    "      #  self.pool1=nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f600188",
   "metadata": {
    "id": "3f600188"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,num_chanel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.input_chanel=num_chanel\n",
    "        self.output_chanel=num_chanel\n",
    "        \n",
    "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
    "        self.act=nn.Tanh()\n",
    "        ## there should not be any MaxPooling layer in the inbetween set\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.act(self.conv(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41ff83cf",
   "metadata": {
    "id": "41ff83cf"
   },
   "outputs": [],
   "source": [
    "# One is responsible for figuring out the unflatten shape\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,unflatten_shape): \n",
    "        super(FullyConnected,self).__init__()\n",
    "        self.unflatten_shape=unflatten_shape\n",
    "        self.fc1=nn.Linear(unflatten_shape,32)\n",
    "        self.ac1=nn.Tanh()\n",
    "        self.fc2=nn.Linear(32,10) \n",
    "        # Let's only tell the airplane from a bird\n",
    "    \n",
    "    def forward(self,x):\n",
    "        inputx=x.view(-1, self.unflatten_shape)\n",
    "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec1467",
   "metadata": {
    "id": "30ec1467"
   },
   "source": [
    "## Stacking up the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0eebf8c6",
   "metadata": {
    "id": "0eebf8c6"
   },
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "class ForwardModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(ForwardModel,self).__init__()\n",
    "        \n",
    "        self.config=config\n",
    "        self.batch_size=self.config.batch_size\n",
    "        self.Ntime=self.config.Ntime\n",
    "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
    "        self.n_layer=self.config.n_layer\n",
    "        self.delta=self.config.totalT/self.Ntime;\n",
    "        \n",
    "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
    "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  BasicBlock(self.config.output_chanel_pj2),\n",
    "                                  FullyConnected(self.config.unflatten_shape)                              \n",
    "        ])\n",
    "        \n",
    "        self.sigma=0.05\n",
    "        \n",
    "    def forwardX(self,x):# here x is the batch collection of images\n",
    "        \n",
    "        # Constructing the noises\n",
    "        # The number 8 is determined from the number of max-pooling size, kernels & paddings etc. \n",
    "        xMat=[]\n",
    "        wMat=torch.FloatTensor(normal.rvs(size=[self.batch_size,\n",
    "                                     self.config.output_chanel_pj2,7,7,\n",
    "                                     self.Ntime]) * self.sqrt_deltaT).to(device)\n",
    "        x0=torch.clone(x).to(device); \n",
    "        xMat.append(x0); \n",
    "        \n",
    "        x_pj1=self.mList[0](x0); \n",
    "        xMat.append(x_pj1.to(device)); \n",
    "        x_input=self.mList[1](x_pj1)\n",
    "        xMat.append(x_input.to(device));\n",
    "        \n",
    "        for i in range(self.Ntime):\n",
    "            # i + 2 because we already have two layers before\n",
    "            xtemp=xMat[i+2]+self.mList[i+2](xMat[i+2])*self.delta #+self.sigma*wMat[:,:,:,:,i] \n",
    "            xMat.append(xtemp.to(device))\n",
    "        \n",
    "        x_terminal=self.mList[-1](xMat[-1])\n",
    "        xMat.append(x_terminal.to(device))\n",
    "        \n",
    "        \n",
    "        return xMat, wMat\n",
    "        \n",
    "        # The input of the target must be a tensor not a list\n",
    "    def backwardYZ(self,xMat,wMat,target):\n",
    "        yMat=[];  \n",
    "        \n",
    "        L=len(xMat)\n",
    "        x_terminal=xMat[-1].to(device)\n",
    "        \n",
    "        loss_val=loss_fn(x_terminal,target.to(device))\n",
    "        loss_val.to(device); \n",
    "        \n",
    "        y_terminal=torch.autograd.grad(outputs=[loss_val], inputs=[x_terminal], grad_outputs=torch.ones_like(loss_val), allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        #Here y_terminal has dim batch_size x output_size (2 x 2)\n",
    "        yMat.append(y_terminal.to(device)); \n",
    "        xtemp=xMat[L-2].to(device) # 3 \n",
    "        \n",
    "        ## Finding Y[T-1]\n",
    "        hami=torch.sum(y_terminal.detach()*self.mList[-1](xtemp),dim=1,keepdim=True) # keep dim=1 is correct\n",
    "        hami=hami.view(-1,1);hami.to(device)\n",
    "\n",
    "        hami_x=torch.autograd.grad(outputs=[hami], inputs=[xtemp], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "        yMat.append(hami_x.to(device))\n",
    "        \n",
    "        for i in range(self.Ntime-1,-1,-1):\n",
    "            X=xMat[i+2].to(device); \n",
    "            hami=torch.sum(yMat[-1].detach()*self.mList[i+2](X),dim=(1,2,3))\n",
    "            hami=hami.view(-1,1); hami.to(device); \n",
    "            \n",
    "            hami_x=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "            ytemp=yMat[-1]+hami_x*self.delta\n",
    "\n",
    "            yMat.append(ytemp.to(device))\n",
    "       \n",
    "    ### Second projection layer\n",
    "        X=xMat[1].to(device); \n",
    "       # X.requires_grad\n",
    "        hami=torch.sum(yMat[-1].detach()*self.mList[1](X),dim=(1,2,3))\n",
    "        hami=hami.view(-1,1); hami.to(device); \n",
    "            \n",
    "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        yMat.append(ytemp.to(device))\n",
    "        \n",
    "        X=xMat[0].to(device); \n",
    "        X.requires_grad=True\n",
    "        hami=torch.sum(yMat[-1].detach()*self.mList[0](X),dim=(1,2,3))\n",
    "        hami=hami.view(-1,1); hami.to(device)\n",
    "            \n",
    "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
    "                                 retain_graph=True, create_graph=True)[0]\n",
    "        yMat.append(ytemp.to(device))\n",
    "        \n",
    "        return yMat  #yMat the order is reversed \n",
    "    \n",
    "    def HamCompute(self,xMat,yMat):\n",
    "        totalham=0.0\n",
    "        \n",
    "        for i in range(self.Ntime+3):\n",
    "            ham_temp=torch.sum(yMat[self.Ntime+2-i].detach()*self.mList[i](xMat[i].detach()) )  #inside the bracket =  +\\small_value * self.batch_size *self.mList[i]*self.mList[i] (No, this doesn't contain batchsize)\n",
    "            totalham+=ham_temp\n",
    "        \n",
    "        return totalham/self.batch_size/(self.Ntime+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9RylV-3v1r1l",
   "metadata": {
    "id": "9RylV-3v1r1l"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_accuracy(train_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for imgs, labels in train_loader:\n",
    "          outputs = net.forwardX(imgs)\n",
    "          _, predicted = torch.max(outputs[0][-1], dim=1)\n",
    "          total += labels.shape[0]\n",
    "          correct += int((predicted == labels.to(device)).sum())\n",
    "  res=correct/total\n",
    "\n",
    "  return res\n",
    "\n",
    "def test_accuracy(val_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for imgs, labels in val_loader:\n",
    "          outputs =net.forwardX(imgs)\n",
    "          _, predicted = torch.max(outputs[0][-1], dim=1)\n",
    "          total += labels.shape[0]\n",
    "          correct += int((predicted == labels.to(device)).sum())\n",
    "  res=correct/total\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f95be8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f95be8f",
    "outputId": "c8dc3024-b2e2-4cdc-d397-9f272ee57773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09989919\n",
      "0.9701\n",
      "0.9701\n",
      "2 0.05897376\n",
      "0.9871\n",
      "0.9871\n",
      "4 0.015559707\n",
      "0.9898\n",
      "0.9898\n",
      "6 0.06452933\n",
      "0.9881\n",
      "0.9881\n",
      "8 0.01710263\n",
      "0.989\n",
      "0.989\n",
      "10 0.003968168\n",
      "0.99\n",
      "0.99\n",
      "12 0.014267882\n",
      "0.9896\n",
      "0.9896\n",
      "14 0.0029396052\n",
      "0.9885\n",
      "0.9885\n",
      "16 0.01590621\n",
      "0.9865\n",
      "0.9865\n",
      "18 0.003950814\n",
      "0.9893\n",
      "0.9893\n"
     ]
    }
   ],
   "source": [
    "n_epoch=20 \n",
    "\n",
    "net=ForwardModel(cfg)\n",
    "net.to(device)\n",
    "\n",
    "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2500,4000], gamma=0.2) \n",
    "\n",
    "Loss_vec=[]\n",
    "training_accuracy=[]\n",
    "testing_accuracy=[]\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "\n",
    "        xmat,wmat=net.forwardX(imgs); \n",
    "        ymat=net.backwardYZ(xmat,wmat.to(device),labels)\n",
    "        loss_temp=net.HamCompute(xmat,ymat)\n",
    "        loss_temp.to(device)\n",
    "        \n",
    "        optimizer.zero_grad();\n",
    "        loss_temp.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch %2 ==0:\n",
    "        loss_val=loss_fn(xmat[-1].to(device),labels.to(device))\n",
    "       # ham_loss=net.HamCompute(xmat,ymat)\n",
    "       # print(ham_loss.cpu().detach().numpy(), loss_val.cpu().detach().numpy())\n",
    "        loss_val_np=loss_val.cpu().detach().numpy()\n",
    "        print(epoch, loss_val_np)\n",
    "        Loss_vec.append(loss_val_np)\n",
    "\n",
    "    #if epoch %10 ==0: \n",
    "        test_temp=test_accuracy(test_loader)\n",
    "        testing_accuracy.append(test_temp)\n",
    "        print(test_temp)\n",
    "\n",
    "        train_temp=train_accuracy(train_loader)\n",
    "        training_accuracy.append(train_temp)\n",
    "        print(test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e9my1LWAid0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e9my1LWAid0",
    "outputId": "b3618a0e-4f94-474c-e047-e886a82415fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "J6qyD-NX9MOu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6qyD-NX9MOu",
    "outputId": "d9609ea8-016d-4955-a569-2149531e5888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cFXQ9zCY9MRP",
   "metadata": {
    "id": "cFXQ9zCY9MRP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bINcmKIydXO",
   "metadata": {
    "id": "3bINcmKIydXO"
   },
   "outputs": [],
   "source": [
    "testing_file = open(\"testing_accuracy\"+str(cfg.batch_size)+\"_003\"+\".txt\", \"w\")\n",
    "np.savetxt(testing_file, testing_accuracy)\n",
    "testing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Y-2IC41ydaE",
   "metadata": {
    "id": "9Y-2IC41ydaE"
   },
   "outputs": [],
   "source": [
    "loss_file = open(\"loss\"+str(cfg.batch_size)+\"_003\"+\".txt\", \"w\")\n",
    "np.savetxt(loss_file, Loss_vec)\n",
    "loss_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yypMY3kW0zS5",
   "metadata": {
    "id": "yypMY3kW0zS5"
   },
   "outputs": [],
   "source": [
    "training_file = open(\"training_accuracy\"+str(cfg.batch_size)+\"_003\"+\".txt\", \"w\")\n",
    "np.savetxt(training_file, training_accuracy)\n",
    "training_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QBHwb01G0zhT",
   "metadata": {
    "id": "QBHwb01G0zhT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6xknonJMydc7",
   "metadata": {
    "id": "6xknonJMydc7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V51y8xbIIdV5",
   "metadata": {
    "id": "V51y8xbIIdV5"
   },
   "outputs": [],
   "source": [
    "for i in range(5, 125,5):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x85ccwLR70wy",
   "metadata": {
    "id": "x85ccwLR70wy"
   },
   "outputs": [],
   "source": [
    "test_accuracy(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4vx-ABYd6RnT",
   "metadata": {
    "id": "4vx-ABYd6RnT"
   },
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.plot(range(5,125,5),Loss_vec)\n",
    "plt.title('Train_loss', fontsize=10)\n",
    "plt.savefig(\"train_loss.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alBtPYQt6Rqb",
   "metadata": {
    "id": "alBtPYQt6Rqb"
   },
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.plot(range(10,130,10),  testing_accuracy)\n",
    "plt.title('testing_accuracy', fontsize=10)\n",
    "plt.savefig(\"testing_accuracy.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jr0Q6mZc6RtV",
   "metadata": {
    "id": "jr0Q6mZc6RtV"
   },
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.plot(range(10,130,10),  training_accuracy)\n",
    "plt.title('training_accuracy', fontsize=10)\n",
    "plt.savefig(\"training_accuracy.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11_eQei6Rwr",
   "metadata": {
    "id": "b11_eQei6Rwr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wF-Ilw7Iv2ZI",
   "metadata": {
    "id": "wF-Ilw7Iv2ZI"
   },
   "source": [
    "The following shows the test accuracy. It is only close to 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cb7sYPgKomXF",
   "metadata": {
    "id": "Cb7sYPgKomXF"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=100,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs =net.forwardX(imgs)\n",
    "        _, predicted = torch.max(outputs[0][-1], dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels.to(device)).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oUBMkccxBoi7",
   "metadata": {
    "id": "oUBMkccxBoi7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VrydbP46Boqz",
   "metadata": {
    "id": "VrydbP46Boqz"
   },
   "outputs": [],
   "source": [
    "test_accuracy(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZabQNnSionjC",
   "metadata": {
    "id": "ZabQNnSionjC"
   },
   "source": [
    "We should test the case where the the data is attacked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MNVnrEbUv8es",
   "metadata": {
    "id": "MNVnrEbUv8es"
   },
   "outputs": [],
   "source": [
    "# Even when we use an average of the estimates, the results don't improve much\n",
    "# at least for this simple case. \n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=100,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kLoVyeFEwCOx",
   "metadata": {
    "id": "kLoVyeFEwCOx"
   },
   "source": [
    "The following is the training accuracy, and we see that it is very close to 1.00. Hence, the constructed neural network clearly has some overtraining issue. We need to use some standard regularization techinques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62811fb6",
   "metadata": {
    "id": "62811fb6"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=100,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1kolLIaHDVW9",
   "metadata": {
    "id": "1kolLIaHDVW9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd19d3",
   "metadata": {
    "id": "79dd19d3"
   },
   "outputs": [],
   "source": [
    "train_accuracy(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176fbb8",
   "metadata": {
    "id": "4176fbb8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08c8f3",
   "metadata": {
    "id": "6d08c8f3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eed3bb",
   "metadata": {
    "id": "40eed3bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55b942",
   "metadata": {
    "id": "ec55b942"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfc9c0",
   "metadata": {
    "id": "90dfc9c0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f3bfb",
   "metadata": {
    "id": "332f3bfb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319adca",
   "metadata": {
    "id": "1319adca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be28a50",
   "metadata": {
    "id": "1be28a50"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_hand_digits.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
