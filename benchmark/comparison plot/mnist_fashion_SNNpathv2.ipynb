{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "64051f42",
      "metadata": {
        "id": "64051f42"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import logging\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from scipy.stats import multivariate_normal as normal\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "sThDQwu9_MY6"
      },
      "id": "sThDQwu9_MY6",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6d9d4a68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d9d4a68",
        "outputId": "5570c890-fd81-42cc-86f2-303d62eae2fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa8242c11f0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a8048c60",
      "metadata": {
        "id": "a8048c60"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "data_type=torch.float32\n",
        "MOMENTUM = 0.99\n",
        "EPSILON = 1e-6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXLxVU3HSjm",
        "outputId": "597fe2ef-62ae-43e1-a964-beffde5517fd"
      },
      "id": "VEXLxVU3HSjm",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "043871cf",
      "metadata": {
        "id": "043871cf"
      },
      "source": [
        "# Handling the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(object):\n",
        "    batch_size = 500\n",
        "\n",
        "    totalT=2.0;\n",
        "\n",
        "    n_layer=Ntime=4;\n",
        "\n",
        "    sqrt_deltaT=np.sqrt(totalT/Ntime);\n",
        "\n",
        "    logging_frequency = 100\n",
        "    verbose = True\n",
        "\n",
        "    input_chanel=1\n",
        "    output_chanel_pj1=32\n",
        "    output_chanel_pj2=16\n",
        "\n",
        "    unflatten_shape=output_chanel_pj2*7*7\n",
        "\n",
        "def get_config(name):\n",
        "    try:\n",
        "        return globals()[name]\n",
        "    except KeyError:\n",
        "        raise KeyError(\"config not defined.\")\n",
        "\n",
        "cfg=get_config('Config')"
      ],
      "metadata": {
        "id": "39nRMtKvCzHs"
      },
      "id": "39nRMtKvCzHs",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e9b3546f",
      "metadata": {
        "scrolled": true,
        "id": "e9b3546f"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "batch_size_train=cfg.batch_size\n",
        "batch_size_test=cfg.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('/files/', train=True, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('/files/', train=False, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=cfg.batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "gM8FBI_d4lLz"
      },
      "id": "gM8FBI_d4lLz",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in test_loader:\n",
        "  print(img.sum())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEv3ave7xpxL",
        "outputId": "04e3733a-cc40-47cb-98ea-7402a263e729"
      },
      "id": "xEv3ave7xpxL",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(209122.0469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "metadata": {
        "id": "n80EcIib4lOl"
      },
      "id": "n80EcIib4lOl",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PqKPJ7UySs6",
        "outputId": "d87bcd34-0e8e-4c8f-e34f-fa2b1e620fa8"
      },
      "id": "3PqKPJ7UySs6",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data.abs().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROet6pFG3re",
        "outputId": "ba082788-067d-452b-9f35-445b03738eae"
      },
      "id": "yROet6pFG3re",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data.abs().max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYHRJxMlGNl_",
        "outputId": "6c42470b-ce25-4748-ee17-4b61141a082e"
      },
      "id": "cYHRJxMlGNl_",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8215)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bceb0197",
      "metadata": {
        "id": "bceb0197"
      },
      "source": [
        "We have stored both the training and the validation datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70444346",
      "metadata": {
        "id": "70444346"
      },
      "source": [
        "Defining the dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78047303",
      "metadata": {
        "id": "78047303"
      },
      "source": [
        "## Defining the configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "be29e470",
      "metadata": {
        "id": "be29e470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfc674b-f0dd-4839-8e0b-fcf987664211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.12158161, -0.11574859,  0.18398867, -0.05220034, -0.14767625,\n",
              "       -0.07879621,  0.09517863,  0.06066116, -0.35531458,  0.06522647])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "normal.rvs(size=[10])*0.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c411bccd",
      "metadata": {
        "id": "c411bccd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "407bcc53",
      "metadata": {
        "id": "407bcc53"
      },
      "source": [
        "# Constructing a dense net"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fefbf48",
      "metadata": {
        "id": "5fefbf48"
      },
      "source": [
        "## Building the building block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "96a33786",
      "metadata": {
        "id": "96a33786"
      },
      "outputs": [],
      "source": [
        "class ProjBlock(nn.Module):\n",
        "    def __init__(self,input_chanel,output_chanel):\n",
        "        super(ProjBlock,self).__init__()\n",
        "        self.input_chanel=input_chanel\n",
        "        self.output_chanel=output_chanel\n",
        "\n",
        "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1)\n",
        "        self.act1=nn.Tanh()\n",
        "        self.pool1=nn.MaxPool2d(2)\n",
        "\n",
        "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1)\n",
        "      #  self.act1=nn.Tanh()\n",
        "      #  self.pool1=nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "3f600188",
      "metadata": {
        "id": "3f600188"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self,num_chanel):\n",
        "        super(BasicBlock,self).__init__()\n",
        "        self.input_chanel=num_chanel\n",
        "        self.output_chanel=num_chanel\n",
        "\n",
        "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
        "        self.act=nn.Tanh()\n",
        "        ## there should not be any MaxPooling layer in the inbetween set\n",
        "\n",
        "    def forward(self,x):\n",
        "        out=self.act(self.conv(x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "41ff83cf",
      "metadata": {
        "id": "41ff83cf"
      },
      "outputs": [],
      "source": [
        "# One is responsible for figuring out the unflatten shape\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self,unflatten_shape):\n",
        "        super(FullyConnected,self).__init__()\n",
        "        self.unflatten_shape=unflatten_shape\n",
        "        self.fc1=nn.Linear(unflatten_shape,32)\n",
        "        self.ac1=nn.Tanh()\n",
        "        self.fc2=nn.Linear(32,10)\n",
        "        # Let's only tell the airplane from a bird\n",
        "\n",
        "    def forward(self,x):\n",
        "        inputx=x.view(-1, self.unflatten_shape)\n",
        "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ec1467",
      "metadata": {
        "id": "30ec1467"
      },
      "source": [
        "## Stacking up the blocks"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGZjVG22QYRe"
      },
      "id": "XGZjVG22QYRe",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal.rvs(size=[2,2],random_state=12345)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQQIQxjQwQf",
        "outputId": "e72e637a-7b2d-4500-ccaf-63137da7b1de"
      },
      "id": "yrQQIQxjQwQf",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20470766,  0.47894334],\n",
              "       [-0.51943872, -0.5557303 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal.rvs(size=[2,2],random_state=12345)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm2CapdrQwS5",
        "outputId": "3426291f-228e-42f5-8214-e77135aeee8d"
      },
      "id": "Pm2CapdrQwS5",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20470766,  0.47894334],\n",
              "       [-0.51943872, -0.5557303 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "0eebf8c6",
      "metadata": {
        "id": "0eebf8c6"
      },
      "outputs": [],
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "class ForwardModel(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(ForwardModel,self).__init__()\n",
        "\n",
        "        self.config=config\n",
        "        self.batch_size=self.config.batch_size\n",
        "        self.Ntime=self.config.Ntime\n",
        "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
        "        self.n_layer=self.config.n_layer\n",
        "        self.delta=self.config.totalT/self.Ntime;\n",
        "\n",
        "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
        "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  FullyConnected(self.config.unflatten_shape)\n",
        "        ])\n",
        "\n",
        "        self.mList_diff=nn.ModuleList([\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2)\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.sigma=4.0\n",
        "\n",
        "    def forwardX(self,x,seed_num):# here x is the batch collection of images\n",
        "\n",
        "        # Constructing the noises\n",
        "        # The number 8 is determined from the number of max-pooling size, kernels & paddings etc.\n",
        "        xMat=[]\n",
        "        wMat=self.sigma*torch.FloatTensor(normal.rvs(size=[self.batch_size,        ### The batch_size for each different data point.\n",
        "                                     self.config.output_chanel_pj2,7,7,\n",
        "                                     self.Ntime],random_state=seed_num) * self.sqrt_deltaT).to(device)\n",
        "        x0=torch.clone(x).to(device);\n",
        "        xMat.append(x0);\n",
        "\n",
        "        x_pj1=self.mList[0](x0);\n",
        "        xMat.append(x_pj1.to(device));\n",
        "        x_input=self.mList[1](x_pj1)\n",
        "        xMat.append(x_input.to(device));\n",
        "\n",
        "        for i in range(self.Ntime):\n",
        "            # i + 2 because we already have two layers before\n",
        "            xtemp=xMat[i+2]+self.mList[i+2](xMat[i+2])*self.delta + self.mList_diff[i](xMat[i+2]) *wMat[:,:,:,:,i] ## torch.sigmoid\n",
        "            xMat.append(xtemp.to(device))\n",
        "\n",
        "        x_terminal=self.mList[-1](xMat[-1])\n",
        "        xMat.append(x_terminal.to(device))\n",
        "\n",
        "        return xMat, wMat\n",
        "\n",
        "        # The input of the target must be a tensor not a list\n",
        "\n",
        "\n",
        "    def backwardYZ(self,xMat,wMat,target):\n",
        "        yMat=[];\n",
        "        zMat=[];\n",
        "\n",
        "\n",
        "        L=len(xMat)\n",
        "        x_terminal=xMat[-1].to(device)\n",
        "\n",
        "        loss_val=loss_fn(x_terminal,target.to(device))\n",
        "        loss_val.to(device);\n",
        "\n",
        "        y_terminal=torch.autograd.grad(outputs=[loss_val], inputs=[x_terminal], grad_outputs=torch.ones_like(loss_val), allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        #Here y_terminal has dim batch_size x output_size (2 x 2)\n",
        "        yMat.append(y_terminal.to(device));\n",
        "        xtemp=xMat[L-2].to(device) # 3\n",
        "\n",
        "        ## Finding Y[T-1]\n",
        "        hami=torch.sum(y_terminal.detach()*self.mList[-1](xtemp),dim=1,keepdim=True) # keep dim=1 is correct\n",
        "        hami=hami.view(-1,1);hami.to(device)\n",
        "\n",
        "        hami_x=torch.autograd.grad(outputs=[hami], inputs=[xtemp], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        yMat.append(hami_x.to(device))\n",
        "\n",
        "        for i in range(self.Ntime-1,-1,-1):\n",
        "######### for Z ##\n",
        "            ztemp=yMat[-1]*wMat[:,:,:,:,i]/self.sqrt_deltaT\n",
        "            zMat.append(ztemp)\n",
        "\n",
        "            X=xMat[i+2].to(device);\n",
        "            hami=torch.sum(yMat[-1].detach()*self.mList[i+2](X) + ztemp.detach()*self.mList_diff[i](X),dim=(1,2,3))\n",
        "            hami=hami.view(-1,1); hami.to(device);\n",
        "\n",
        "            hami_x=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "            ytemp=yMat[-1]+hami_x*self.delta\n",
        "\n",
        "            yMat.append(ytemp.to(device))\n",
        "\n",
        "    ### Second projection layer\n",
        "        X=xMat[1].to(device);\n",
        "       # X.requires_grad\n",
        "        hami=torch.sum(yMat[-1].detach()*self.mList[1](X),dim=(1,2,3))\n",
        "        hami=hami.view(-1,1); hami.to(device);\n",
        "\n",
        "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        yMat.append(ytemp.to(device))\n",
        "\n",
        "        X=xMat[0].to(device);\n",
        "        X.requires_grad=True\n",
        "        hami=torch.sum(yMat[-1].detach()*self.mList[0](X),dim=(1,2,3))\n",
        "        hami=hami.view(-1,1); hami.to(device)\n",
        "\n",
        "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        yMat.append(ytemp.to(device))\n",
        "\n",
        "        return yMat,zMat  #yMat the order is reversed\n",
        "\n",
        "\n",
        "    def HamCompute(self,xMat,yMat,zMat):\n",
        "        totalham=0.0\n",
        "       # l2_norm=sum(p.pow(2.0).sum() for p in self.parameters() )\n",
        "        for i in range(self.Ntime+3):\n",
        "            ham_temp=torch.sum(yMat[self.Ntime+2-i].detach()*self.mList[i](xMat[i].detach()) )  #inside the bracket =  +\\small_value * self.batch_size *self.mList[i]*self.mList[i] (No, this doesn't contain batchsize)\n",
        "            totalham+=ham_temp\n",
        "        for i in range(self.Ntime-1, -1 , -1):\n",
        "          ham_temp=torch.sum(zMat[i].detach()*self.mList_diff[i](xMat[i+2].detach()))\n",
        "          totalham+=ham_temp\n",
        "        #totalham+=l2_norm*0.001\n",
        "        return totalham/self.batch_size/(self.Ntime+3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_accuracy(train_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      seed_t=0\n",
        "      for imgs, labels in train_loader:\n",
        "          outputs = net.forwardX(imgs,seed_t)\n",
        "          _, predicted = torch.max(outputs[0][-1], dim=1)\n",
        "          total += labels.shape[0]\n",
        "          correct += int((predicted == labels.to(device)).sum())\n",
        "          seed_t=seed_t+1\n",
        "  res=correct/total\n",
        "\n",
        "  return res\n",
        "\n",
        "def avg_predictionSeed(model,iters,imgs,labels):\n",
        "    temp=torch.zeros((cfg.batch_size,10))\n",
        "    temp=temp.to(device)\n",
        "    for i in range(iters):\n",
        "        val,_=model.forwardX(imgs,np.random.randint(1000000))\n",
        "        temp+=val[-1].to(device)\n",
        "    temp=temp/iters;\n",
        "    _,predicts=torch.max(temp,dim=1)\n",
        "    return predicts\n",
        "\n",
        "\n",
        "def test_accuracy(val_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "### One the other hand, it may be only reasonable to use\n",
        "  with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "       #   outputs =net.forwardX(imgs,np.random.randint(1000))\n",
        "       #   _, predicted = torch.max(outputs[0][-1], dim=1)\n",
        "          predicted=avg_predictionSeed(net,5,imgs,labels)\n",
        "          total += labels.shape[0]\n",
        "          correct += int((predicted == labels.to(device)).sum())\n",
        "  res=correct/total\n",
        "  return res"
      ],
      "metadata": {
        "id": "9RylV-3v1r1l"
      },
      "id": "9RylV-3v1r1l",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-iyNGxK0SWp"
      },
      "id": "e-iyNGxK0SWp",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch=10\n",
        "\n",
        "net=ForwardModel(cfg)\n",
        "net.to(device)\n",
        "\n",
        "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2500,4000], gamma=0.2)\n",
        "\n",
        "Loss_vec=[]\n",
        "training_accuracy=[]\n",
        "testing_accuracy=[]\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    seed_n=0\n",
        "    for imgs, labels in train_loader:\n",
        "\n",
        "        xmat,wmat=net.forwardX(imgs,seed_n);\n",
        "        ymat,zmat=net.backwardYZ(xmat,wmat.to(device),labels)\n",
        "        loss_temp=net.HamCompute(xmat,ymat,zmat)\n",
        "        loss_temp.to(device)\n",
        "\n",
        "        optimizer.zero_grad();\n",
        "        loss_temp.backward()\n",
        "        optimizer.step()\n",
        "        seed_n=seed_n+1\n",
        "\n",
        "    if epoch %1 ==0:\n",
        "      print(epoch)\n",
        "      loss_val=loss_fn(xmat[-1].to(device),labels.to(device))\n",
        "      loss_val_np=loss_val.cpu().detach().numpy()\n",
        "      print(loss_val_np)\n",
        "      Loss_vec.append(loss_val_np)\n",
        "\n",
        "      test_temp=test_accuracy(test_loader)\n",
        "      testing_accuracy.append(test_temp)\n",
        "      print(test_temp)\n",
        "\n",
        "      train_temp=train_accuracy(train_loader)\n",
        "      training_accuracy.append(train_temp)\n",
        "      print(train_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQCOsVqdE1Tr",
        "outputId": "6eb4ad6c-334d-4753-b9bb-4076d28dc3a3"
      },
      "id": "yQCOsVqdE1Tr",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0.84447956\n",
            "0.7065\n",
            "0.6846666666666666\n",
            "1\n",
            "0.68417037\n",
            "0.7415\n",
            "0.7391833333333333\n",
            "2\n",
            "0.62124497\n",
            "0.7625\n",
            "0.7634166666666666\n",
            "3\n",
            "0.5981893\n",
            "0.7746\n",
            "0.7771166666666667\n",
            "4\n",
            "0.59521616\n",
            "0.7767\n",
            "0.7827666666666667\n",
            "5\n",
            "0.593731\n",
            "0.7731\n",
            "0.7833333333333333\n",
            "6\n",
            "0.5604158\n",
            "0.7878\n",
            "0.79515\n",
            "7\n",
            "0.5441509\n",
            "0.7943\n",
            "0.7971166666666667\n",
            "8\n",
            "0.54203355\n",
            "0.7905\n",
            "0.79775\n",
            "9\n",
            "0.49463117\n",
            "0.7965\n",
            "0.80195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SNfMfoSEh2uC"
      },
      "id": "SNfMfoSEh2uC",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(training_accuracy).to_csv(\"02_snnTrain.csv\")\n",
        "#pd.DataFrame(testing_accuracy).to_csv(\"02_snnTest.csv\")"
      ],
      "metadata": {
        "id": "XdWQoHvTE1WH"
      },
      "id": "XdWQoHvTE1WH",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Adv Attack"
      ],
      "metadata": {
        "id": "TMvvt2OhgeSf"
      },
      "id": "TMvvt2OhgeSf"
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval();"
      ],
      "metadata": {
        "id": "vGYxv8b8gqpg"
      },
      "id": "vGYxv8b8gqpg",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FGSM attack code\n",
        "# which also works in the batch case\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "#    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "iRR4J4wBgmKr"
      },
      "id": "iRR4J4wBgmKr",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_prediction(model,iters,imgs,labels):\n",
        "    temp=torch.zeros((cfg.batch_size,10))\n",
        "    temp=temp.to(device)\n",
        "    for i in range(iters):\n",
        "        val,_=model.forwardX(imgs)\n",
        "        temp+=val[-1].to(device)\n",
        "    temp=temp/iters;\n",
        "    _,predicts=torch.max(temp,dim=1)\n",
        "    return predicts"
      ],
      "metadata": {
        "id": "LFB9Cr2vBNML"
      },
      "id": "LFB9Cr2vBNML",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,device, epsilon, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    correct_avg=0\n",
        "\n",
        "    for imgs, labels in test_loader:\n",
        "\n",
        "        imgs, labels=imgs.to(device), labels.to(device)\n",
        "        imgs.requires_grad=True\n",
        "        xm,wm=model.forwardX(imgs,np.random.randint(1000))\n",
        "        loss=loss_fn(xm[-1].to(device),labels)\n",
        "        _,predict_init=torch.max(xm[-1],dim=1)\n",
        "\n",
        "\n",
        "        model.zero_grad()\n",
        "   #     # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "        data_grad=imgs.grad.data\n",
        "        perturbed_data = fgsm_attack(imgs, epsilon, data_grad)\n",
        "\n",
        "   #     output,_ = model.forwardX(perturbed_data)\n",
        "\n",
        "   #     _,predict_final=torch.max(output[-1],dim=1)\n",
        "\n",
        "        predict_final_avg=avg_predictionSeed(net,10,perturbed_data,labels)\n",
        "\n",
        "     #   correct += int((predict_final == labels.to(device)).sum())\n",
        "        correct_avg += int((predict_final_avg.to(device) == labels.to(device)).sum())\n",
        "        total += imgs.shape[0]\n",
        "    return  correct_avg/total # correct/total,"
      ],
      "metadata": {
        "id": "awQUAAoHBNO9"
      },
      "id": "awQUAAoHBNO9",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0,.05,.1,.15,0.2, 0.3,0.4,0.5]"
      ],
      "metadata": {
        "id": "XIOxQ8bABNRp"
      },
      "id": "XIOxQ8bABNRp",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "332f3bfb",
      "metadata": {
        "id": "332f3bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0cda4d-96e6-4b96-9de4-a28c8e151a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8046\n",
            "0.7824\n",
            "0.7551\n",
            "0.7235\n",
            "0.6944\n",
            "0.6206\n",
            "0.5494\n",
            "0.4934\n"
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc = test(net, device, eps, test_loader)\n",
        "    print(acc)\n",
        "    accuracies.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1319adca",
      "metadata": {
        "id": "1319adca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be28a50",
      "metadata": {
        "id": "1be28a50"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}