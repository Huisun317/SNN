{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64051f42"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import logging\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from scipy.stats import multivariate_normal as normal\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ],
      "id": "64051f42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sThDQwu9_MY6"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "id": "sThDQwu9_MY6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d9d4a68",
        "outputId": "821ba018-8aed-4d1c-b5db-004129d6ddcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f98b8dd5130>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)"
      ],
      "id": "6d9d4a68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8048c60"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ],
      "id": "a8048c60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXLxVU3HSjm",
        "outputId": "b9fe6573-cb25-4158-e73e-1838d269eaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "data_type=torch.float32\n",
        "MOMENTUM = 0.99\n",
        "EPSILON = 1e-6"
      ],
      "id": "VEXLxVU3HSjm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "043871cf"
      },
      "source": [
        "# Handling the data"
      ],
      "id": "043871cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39nRMtKvCzHs"
      },
      "outputs": [],
      "source": [
        "class Config(object):\n",
        "    batch_size = 500\n",
        "\n",
        "    totalT=2.0;\n",
        "\n",
        "    n_layer=Ntime=4;\n",
        "\n",
        "    sqrt_deltaT=np.sqrt(totalT/Ntime);\n",
        "\n",
        "    logging_frequency = 100\n",
        "    verbose = True\n",
        "\n",
        "    input_chanel=1\n",
        "    output_chanel_pj1=32\n",
        "    output_chanel_pj2=16\n",
        "\n",
        "    unflatten_shape=output_chanel_pj2*7*7\n",
        "\n",
        "def get_config(name):\n",
        "    try:\n",
        "        return globals()[name]\n",
        "    except KeyError:\n",
        "        raise KeyError(\"config not defined.\")\n",
        "\n",
        "cfg=get_config('Config')"
      ],
      "id": "39nRMtKvCzHs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9b3546f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "batch_size_train=cfg.batch_size\n",
        "batch_size_test=cfg.batch_size"
      ],
      "id": "e9b3546f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM8FBI_d4lLz",
        "outputId": "33d2fe34-b32b-4ae0-94a0-9c7013cbe34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /files/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 6870912.24it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/FashionMNIST/raw/train-images-idx3-ubyte.gz to /files/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /files/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 58107.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /files/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /files/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:02<00:00, 2196812.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /files/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /files/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6693204.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /files/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /files/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('/files/', train=True, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=cfg.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.FashionMNIST('/files/', train=False, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])), batch_size=cfg.batch_size, shuffle=True)"
      ],
      "id": "gM8FBI_d4lLz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n80EcIib4lOl"
      },
      "outputs": [],
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "id": "n80EcIib4lOl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bceb0197"
      },
      "source": [
        "We have stored both the training and the validation datasets"
      ],
      "id": "bceb0197"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70444346"
      },
      "source": [
        "Defining the dataloader"
      ],
      "id": "70444346"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78047303"
      },
      "source": [
        "## Defining the configuration"
      ],
      "id": "78047303"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be29e470"
      },
      "outputs": [],
      "source": [],
      "id": "be29e470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c411bccd"
      },
      "outputs": [],
      "source": [],
      "id": "c411bccd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "407bcc53"
      },
      "source": [
        "# Constructing a dense net"
      ],
      "id": "407bcc53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fefbf48"
      },
      "source": [
        "## Building the building block"
      ],
      "id": "5fefbf48"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96a33786"
      },
      "outputs": [],
      "source": [
        "class ProjBlock(nn.Module):\n",
        "    def __init__(self,input_chanel,output_chanel):\n",
        "        super(ProjBlock,self).__init__()\n",
        "        self.input_chanel=input_chanel\n",
        "        self.output_chanel=output_chanel\n",
        "\n",
        "        self.conv1=nn.Conv2d(input_chanel,output_chanel,kernel_size=3,padding=1)\n",
        "        self.act1=nn.Tanh()\n",
        "        self.pool1=nn.MaxPool2d(2)\n",
        "\n",
        "      #  self.conv2=nn.Conv2d(2*output_chanel,output_chanel,kernel_size=3,padding=1)\n",
        "      #  self.act1=nn.Tanh()\n",
        "      #  self.pool1=nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "      #  out = self.pool2(self.act2(self.conv2(x)))\n",
        "        return out"
      ],
      "id": "96a33786"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f600188"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self,num_chanel):\n",
        "        super(BasicBlock,self).__init__()\n",
        "        self.input_chanel=num_chanel\n",
        "        self.output_chanel=num_chanel\n",
        "\n",
        "        self.conv=nn.Conv2d(self.input_chanel,self.output_chanel,kernel_size=3,padding=1)\n",
        "        self.act=nn.Tanh()\n",
        "        ## there should not be any MaxPooling layer in the inbetween set\n",
        "\n",
        "    def forward(self,x):\n",
        "        out=self.act(self.conv(x))\n",
        "        return out"
      ],
      "id": "3f600188"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41ff83cf"
      },
      "outputs": [],
      "source": [
        "# One is responsible for figuring out the unflatten shape\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self,unflatten_shape):\n",
        "        super(FullyConnected,self).__init__()\n",
        "        self.unflatten_shape=unflatten_shape\n",
        "        self.fc1=nn.Linear(unflatten_shape,32)\n",
        "        self.ac1=nn.Tanh()\n",
        "        self.fc2=nn.Linear(32,10)\n",
        "        # Let's only tell the airplane from a bird\n",
        "\n",
        "    def forward(self,x):\n",
        "        inputx=x.view(-1, self.unflatten_shape)\n",
        "        out=self.fc2(self.ac1(self.fc1(inputx)))\n",
        "        return out"
      ],
      "id": "41ff83cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ec1467"
      },
      "source": [
        "## Stacking up the blocks"
      ],
      "id": "30ec1467"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eebf8c6"
      },
      "outputs": [],
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "class ForwardModel(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(ForwardModel,self).__init__()\n",
        "\n",
        "        self.config=config\n",
        "        self.batch_size=self.config.batch_size\n",
        "        self.Ntime=self.config.Ntime\n",
        "        self.sqrt_deltaT=self.config.sqrt_deltaT;\n",
        "        self.n_layer=self.config.n_layer\n",
        "        self.delta=self.config.totalT/self.Ntime;\n",
        "\n",
        "        self.mList=nn.ModuleList([ProjBlock(self.config.input_chanel,self.config.output_chanel_pj1),\n",
        "                                  ProjBlock(self.config.output_chanel_pj1,self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  BasicBlock(self.config.output_chanel_pj2),\n",
        "                                  FullyConnected(self.config.unflatten_shape)\n",
        "        ])\n",
        "\n",
        "        self.sigma=2.0\n",
        "\n",
        "    def forwardX(self,x):# here x is the batch collection of images\n",
        "\n",
        "        # Constructing the noises\n",
        "        # The number 8 is determined from the number of max-pooling size, kernels & paddings etc.\n",
        "        xMat=[]\n",
        "        wMat=torch.FloatTensor(normal.rvs(size=[self.batch_size,\n",
        "                                     self.config.output_chanel_pj2,7,7,\n",
        "                                     self.Ntime]) * self.sqrt_deltaT).to(device)\n",
        "        x0=torch.clone(x).to(device);\n",
        "        xMat.append(x0);\n",
        "\n",
        "        x_pj1=self.mList[0](x0);\n",
        "        xMat.append(x_pj1.to(device));\n",
        "        x_input=self.mList[1](x_pj1)\n",
        "        xMat.append(x_input.to(device));\n",
        "\n",
        "        for i in range(self.Ntime):\n",
        "            # i + 2 because we already have two layers before\n",
        "            xtemp=xMat[i+2]+self.mList[i+2](xMat[i+2])*self.delta +self.sigma*wMat[:,:,:,:,i]\n",
        "            xMat.append(xtemp.to(device))\n",
        "\n",
        "        x_terminal=self.mList[-1](xMat[-1])\n",
        "        xMat.append(x_terminal.to(device))\n",
        "\n",
        "\n",
        "        return xMat, wMat\n",
        "\n",
        "        # The input of the target must be a tensor not a list\n",
        "    def backwardYZ(self,xMat,wMat,target):\n",
        "        yMat=[];\n",
        "\n",
        "        L=len(xMat)\n",
        "        x_terminal=xMat[-1].to(device)\n",
        "\n",
        "        loss_val=loss_fn(x_terminal,target.to(device))\n",
        "        loss_val.to(device);\n",
        "\n",
        "        y_terminal=torch.autograd.grad(outputs=[loss_val], inputs=[x_terminal], grad_outputs=torch.ones_like(loss_val), allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        #Here y_terminal has dim batch_size x output_size (2 x 2)\n",
        "        yMat.append(y_terminal.to(device));\n",
        "        xtemp=xMat[L-2].to(device) # 3\n",
        "\n",
        "        ## Finding Y[T-1]\n",
        "        hami=torch.sum(y_terminal.detach()*self.mList[-1](xtemp),dim=1,keepdim=True) # keep dim=1 is correct\n",
        "        hami=hami.view(-1,1);hami.to(device)\n",
        "\n",
        "        hami_x=torch.autograd.grad(outputs=[hami], inputs=[xtemp], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        yMat.append(hami_x.to(device))\n",
        "\n",
        "        for i in range(self.Ntime-1,-1,-1):\n",
        "            X=xMat[i+2].to(device);\n",
        "            hami=torch.sum(yMat[-1].detach()*self.mList[i+2](X),dim=(1,2,3))\n",
        "            hami=hami.view(-1,1); hami.to(device);\n",
        "\n",
        "            hami_x=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "            ytemp=yMat[-1]+hami_x*self.delta\n",
        "\n",
        "            yMat.append(ytemp.to(device))\n",
        "\n",
        "    ### Second projection layer\n",
        "        X=xMat[1].to(device);\n",
        "       # X.requires_grad\n",
        "        hami=torch.sum(yMat[-1].detach()*self.mList[1](X),dim=(1,2,3))\n",
        "        hami=hami.view(-1,1); hami.to(device);\n",
        "\n",
        "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        yMat.append(ytemp.to(device))\n",
        "\n",
        "        X=xMat[0].to(device);\n",
        "        X.requires_grad=True\n",
        "        hami=torch.sum(yMat[-1].detach()*self.mList[0](X),dim=(1,2,3))\n",
        "        hami=hami.view(-1,1); hami.to(device)\n",
        "\n",
        "        ytemp=torch.autograd.grad(outputs=[hami], inputs=[X], grad_outputs=torch.ones_like(hami),allow_unused=True,\n",
        "                                 retain_graph=True, create_graph=True)[0]\n",
        "        yMat.append(ytemp.to(device))\n",
        "\n",
        "        return yMat  #yMat the order is reversed\n",
        "\n",
        "    def HamCompute(self,xMat,yMat):\n",
        "        totalham=0.0\n",
        "       # l2_norm=sum(p.pow(2.0).sum() for p in self.parameters() )\n",
        "        for i in range(self.Ntime+3):\n",
        "            ham_temp=torch.sum(yMat[self.Ntime+2-i].detach()*self.mList[i](xMat[i].detach()) )  #inside the bracket =  +\\small_value * self.batch_size *self.mList[i]*self.mList[i] (No, this doesn't contain batchsize)\n",
        "            totalham+=ham_temp\n",
        "        #totalham+=l2_norm*0.001\n",
        "        return totalham/self.batch_size/(self.Ntime+3)"
      ],
      "id": "0eebf8c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RylV-3v1r1l"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_accuracy(train_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for imgs, labels in train_loader:\n",
        "          outputs = net.forwardX(imgs)\n",
        "          _, predicted = torch.max(outputs[0][-1], dim=1)\n",
        "          total += labels.shape[0]\n",
        "          correct += int((predicted == labels.to(device)).sum())\n",
        "  res=correct/total\n",
        "\n",
        "  return res\n",
        "\n",
        "def test_accuracy(val_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "          outputs =net.forwardX(imgs)\n",
        "          _, predicted = torch.max(outputs[0][-1], dim=1)\n",
        "          total += labels.shape[0]\n",
        "          correct += int((predicted == labels.to(device)).sum())\n",
        "  res=correct/total\n",
        "  return res"
      ],
      "id": "9RylV-3v1r1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQCOsVqdE1Tr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "58b7a956-b2d3-40cd-aa09-b0d3ec79ae8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.66252136\n",
            "0.7394\n",
            "0.7492666666666666\n",
            "1 0.6567129\n",
            "0.7879\n",
            "0.7936\n",
            "2 0.58137846\n",
            "0.8013\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4f1f12ecbd2c>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mtrain_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5b3dd7ae1419>\u001b[0m in \u001b[0;36mtrain_accuracy\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforwardX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_epoch=10\n",
        "\n",
        "net=ForwardModel(cfg)\n",
        "net.to(device)\n",
        "\n",
        "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2500,4000], gamma=0.2)\n",
        "\n",
        "Loss_vec=[]\n",
        "training_accuracy=[]\n",
        "testing_accuracy=[]\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    for imgs, labels in train_loader:\n",
        "\n",
        "\n",
        "        xmat,wmat=net.forwardX(imgs);\n",
        "        ymat=net.backwardYZ(xmat,wmat.to(device),labels)\n",
        "        loss_temp=net.HamCompute(xmat,ymat)\n",
        "        loss_temp.to(device)\n",
        "\n",
        "        optimizer.zero_grad();\n",
        "        loss_temp.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch %1 ==0:\n",
        "        loss_val=loss_fn(xmat[-1].to(device),labels.to(device))\n",
        "       # ham_loss=net.HamCompute(xmat,ymat)\n",
        "       # print(ham_loss.cpu().detach().numpy(), loss_val.cpu().detach().numpy())\n",
        "        loss_val_np=loss_val.cpu().detach().numpy()\n",
        "        print(epoch, loss_val_np)\n",
        "        Loss_vec.append(loss_val_np)\n",
        "\n",
        "    #if epoch %10 ==0:\n",
        "        test_temp=test_accuracy(test_loader)\n",
        "        testing_accuracy.append(test_temp)\n",
        "        print(test_temp)\n",
        "\n",
        "        train_temp=train_accuracy(train_loader)\n",
        "        training_accuracy.append(train_temp)\n",
        "        print(train_temp)"
      ],
      "id": "yQCOsVqdE1Tr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdWQoHvTE1WH"
      },
      "outputs": [],
      "source": [],
      "id": "XdWQoHvTE1WH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOeADJH9E1Ya"
      },
      "outputs": [],
      "source": [],
      "id": "ZOeADJH9E1Ya"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rzfS1xf9V-V",
        "outputId": "3cc15f96-90ef-4c36-ac27-0f9391c65cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.4600175\n",
            "0.8342\n",
            "0.84065\n",
            "1 0.3930344\n",
            "0.8601\n",
            "0.8712166666666666\n",
            "2 0.3804343\n",
            "0.8762\n",
            "0.8894166666666666\n",
            "3 0.31233355\n",
            "0.8764\n",
            "0.8934\n",
            "4 0.33462223\n",
            "0.89\n",
            "0.9055\n",
            "5 0.2883765\n",
            "0.8934\n",
            "0.9103166666666667\n",
            "6 0.24727301\n",
            "0.8978\n",
            "0.9158166666666666\n",
            "7 0.24122407\n",
            "0.8946\n",
            "0.9167\n",
            "8 0.22976273\n",
            "0.9036\n",
            "0.9237166666666666\n",
            "9 0.25150692\n",
            "0.908\n",
            "0.9311\n",
            "10 0.23556092\n",
            "0.9021\n",
            "0.9269833333333334\n",
            "11 0.20559546\n",
            "0.9096\n",
            "0.9346166666666667\n",
            "12 0.20727155\n",
            "0.9073\n",
            "0.9358333333333333\n",
            "13 0.16154906\n",
            "0.9059\n",
            "0.936\n",
            "14 0.17529136\n",
            "0.9134\n",
            "0.9409333333333333\n",
            "15 0.15335551\n",
            "0.9096\n",
            "0.944\n",
            "16 0.19574562\n",
            "0.9133\n",
            "0.948\n",
            "17 0.14522822\n",
            "0.9152\n",
            "0.9506\n",
            "18 0.12336541\n",
            "0.911\n",
            "0.9519\n",
            "19 0.105183505\n",
            "0.9147\n",
            "0.9537166666666667\n"
          ]
        }
      ],
      "source": [
        "n_epoch=20\n",
        "\n",
        "net=ForwardModel(cfg)\n",
        "net.to(device)\n",
        "\n",
        "optimizer=optim.Adam(net.parameters(), lr=1.5e-3)#it could be a bad idea to add weight decay\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2500,4000], gamma=0.2)\n",
        "\n",
        "Loss_vec=[]\n",
        "training_accuracy=[]\n",
        "testing_accuracy=[]\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    for imgs, labels in train_loader:\n",
        "\n",
        "\n",
        "        xmat,wmat=net.forwardX(imgs);\n",
        "        ymat=net.backwardYZ(xmat,wmat.to(device),labels)\n",
        "        loss_temp=net.HamCompute(xmat,ymat)\n",
        "        loss_temp.to(device)\n",
        "\n",
        "        optimizer.zero_grad();\n",
        "        loss_temp.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch %1 ==0:\n",
        "        loss_val=loss_fn(xmat[-1].to(device),labels.to(device))\n",
        "       # ham_loss=net.HamCompute(xmat,ymat)\n",
        "       # print(ham_loss.cpu().detach().numpy(), loss_val.cpu().detach().numpy())\n",
        "        loss_val_np=loss_val.cpu().detach().numpy()\n",
        "        print(epoch, loss_val_np)\n",
        "        Loss_vec.append(loss_val_np)\n",
        "\n",
        "    #if epoch %10 ==0:\n",
        "        test_temp=test_accuracy(test_loader)\n",
        "        testing_accuracy.append(test_temp)\n",
        "        print(test_temp)\n",
        "\n",
        "        train_temp=train_accuracy(train_loader)\n",
        "        training_accuracy.append(train_temp)\n",
        "        print(train_temp)"
      ],
      "id": "-rzfS1xf9V-V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4176fbb8"
      },
      "outputs": [],
      "source": [],
      "id": "4176fbb8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d08c8f3"
      },
      "outputs": [],
      "source": [],
      "id": "6d08c8f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40eed3bb"
      },
      "outputs": [],
      "source": [],
      "id": "40eed3bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec55b942"
      },
      "outputs": [],
      "source": [],
      "id": "ec55b942"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90dfc9c0"
      },
      "outputs": [],
      "source": [],
      "id": "90dfc9c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "332f3bfb"
      },
      "outputs": [],
      "source": [],
      "id": "332f3bfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1319adca"
      },
      "outputs": [],
      "source": [],
      "id": "1319adca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1be28a50"
      },
      "outputs": [],
      "source": [],
      "id": "1be28a50"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}